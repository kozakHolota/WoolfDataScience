{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Градієнтний спуск\n",
    "\n",
    "## Генеруємо дані"
   ],
   "id": "39908c67940a607b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.251286Z",
     "start_time": "2025-10-01T20:02:15.248985Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_np = np.random.rand(100, 2)\n",
    "sample_np.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 248
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Створюємо поліном",
   "id": "31457297b757e6ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.273496Z",
     "start_time": "2025-10-01T20:02:15.271464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sympy import symbols\n",
    "\n",
    "\n",
    "def polynomial():\n",
    "    x1 = symbols('x1')\n",
    "    x2 = symbols('x2')\n",
    "    return 4*x1**2 + 5*x2**2 + 2*x1*x2 + 3*x1 - 6*x2"
   ],
   "id": "51efeb8f699f08e8",
   "outputs": [],
   "execution_count": 249
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Функція простого градієнтного спуску",
   "id": "2e3bb0ea11119766"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.278897Z",
     "start_time": "2025-10-01T20:02:15.276301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sympy import Poly, lambdify\n",
    "\n",
    "\n",
    "def polynomial_regression_gradient_descent(features: np.ndarray, poloinomial_func, learning_rate: float, epochs: int):\n",
    "    # Визначаємо степінь полінома з символьного виразу\n",
    "    ploinomial_rate = Poly(poloinomial_func).total_degree()\n",
    "\n",
    "    # Готуємо ціль як значення полінома на даних\n",
    "    x1, x2 = symbols('x1 x2')\n",
    "    f = lambdify((x1, x2), poloinomial_func, modules='numpy')\n",
    "    y = f(features[:, 0], features[:, 1]).astype(float).reshape(-1)  # (m,)\n",
    "\n",
    "    # Узгоджено генеруємо поліноміальні ознаки у train\n",
    "    poly = PolynomialFeatures(degree=ploinomial_rate, include_bias=True)\n",
    "    X_poly = poly.fit_transform(features)  # (m, p)\n",
    "    m, p = X_poly.shape\n",
    "\n",
    "    # Ключова правка: довжина theta дорівнює кількості колонок у X_poly\n",
    "    theta = np.zeros(p, dtype=float)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X_poly @ theta          # (m,)\n",
    "        error = y_pred - y               # (m,)\n",
    "        gradient = (2.0 / m) * (X_poly.T @ error)  # (p,)\n",
    "        theta -= learning_rate * gradient\n",
    "\n",
    "    return theta"
   ],
   "id": "adc76f33c4457afb",
   "outputs": [],
   "execution_count": 250
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Функція градієнтного спуску методом SGD",
   "id": "ac13ab2d2ca54afa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.283786Z",
     "start_time": "2025-10-01T20:02:15.281099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def polynomial_regression_SGD(features: np.ndarray, poloinomial_func, learning_rate: float, epochs: int, shuffle: bool = True):\n",
    "    # 1) Цільові значення з символічного полінома\n",
    "    x1, x2 = symbols('x1 x2')\n",
    "    f = lambdify((x1, x2), poloinomial_func, modules='numpy')\n",
    "    y = f(features[:, 0], features[:, 1]).astype(float).reshape(-1)  # (m,)\n",
    "\n",
    "    # 2) Поліноміальні ознаки узгоджено з іншими функціями\n",
    "    ploinomial_rate = Poly(poloinomial_func).total_degree()\n",
    "    poly = PolynomialFeatures(degree=ploinomial_rate, include_bias=True)\n",
    "    X_poly = poly.fit_transform(features)  # (m, p)\n",
    "    m, p = X_poly.shape\n",
    "\n",
    "    # 3) Ініціалізація ваг\n",
    "    theta = np.zeros(p, dtype=float)\n",
    "\n",
    "    # 4) Класичний SGD: обхід по зразках\n",
    "    for _ in range(epochs):\n",
    "        if shuffle:\n",
    "            perm = np.random.permutation(m)\n",
    "            X_poly_epoch = X_poly[perm]\n",
    "            y_epoch = y[perm]\n",
    "        else:\n",
    "            X_poly_epoch = X_poly\n",
    "            y_epoch = y\n",
    "\n",
    "        for i in range(m):\n",
    "            xi = X_poly_epoch[i]          # (p,)\n",
    "            yi = y_epoch[i]               # scalar\n",
    "            y_pred_i = xi @ theta         # scalar\n",
    "            error_i = y_pred_i - yi       # scalar\n",
    "            grad_i = 2.0 * xi * error_i   # (p,)\n",
    "            theta -= learning_rate * grad_i\n",
    "\n",
    "    return theta\n"
   ],
   "id": "75448e384de68249",
   "outputs": [],
   "execution_count": 251
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Функція градієнтного спуску методом RMSPROP",
   "id": "f4bd5eb987b694be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.288577Z",
     "start_time": "2025-10-01T20:02:15.285988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def polynomial_regression_rmsprop(features: np.ndarray, poloinomial_func, learning_rate: float, epochs: int, gamma = 0.9, epsilon = 1e-8):\n",
    "    # 1) Цільові значення з символічного полінома\n",
    "    x1, x2 = symbols('x1 x2')\n",
    "    f = lambdify((x1, x2), poloinomial_func, modules='numpy')\n",
    "    y = f(features[:, 0], features[:, 1]).astype(float).reshape(-1)  # (m,)\n",
    "\n",
    "    # 2) Поліноміальні ознаки узгоджено з іншими функціями (include_bias=True)\n",
    "    ploinomial_rate = Poly(poloinomial_func).total_degree()\n",
    "    poly = PolynomialFeatures(degree=ploinomial_rate, include_bias=True)\n",
    "    X_poly = poly.fit_transform(features)  # (m, p)\n",
    "    m, p = X_poly.shape\n",
    "\n",
    "    # 3) Ініціалізація ваг та накопичувача квадратів градієнтів\n",
    "    theta = np.zeros(p, dtype=float)\n",
    "    eg2 = np.zeros(p, dtype=float)\n",
    "\n",
    "    # 4) RMSProp із повним батчем\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X_poly @ theta                 # (m,)\n",
    "        error = y_pred - y                      # (m,)\n",
    "        grad = (2.0 / m) * (X_poly.T @ error)   # (p,)\n",
    "\n",
    "        eg2 = gamma * eg2 + (1.0 - gamma) * (grad ** 2)     # (p,)\n",
    "        theta -= (learning_rate / (np.sqrt(eg2) + epsilon)) * grad\n",
    "\n",
    "    return theta"
   ],
   "id": "75321888651715c4",
   "outputs": [],
   "execution_count": 252
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Функція градієнтного спуску методом ADAM",
   "id": "aaf747d7f0b464c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.293720Z",
     "start_time": "2025-10-01T20:02:15.290921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def polynomial_regression_adam(features: np.ndarray, poloinomial_func, learning_rate: float, epochs: int, beta1=0.9, beta2=0.999, epsilon = 1e-8):\n",
    "    # 1) Цільові значення з символічного полінома\n",
    "    x1, x2 = symbols('x1 x2')\n",
    "    f = lambdify((x1, x2), poloinomial_func, modules='numpy')\n",
    "    y = f(features[:, 0], features[:, 1]).astype(float).reshape(-1)  # (m,)\n",
    "\n",
    "    # 2) Поліноміальні ознаки узгоджено з іншими функціями (include_bias=True)\n",
    "    ploinomial_rate = Poly(poloinomial_func).total_degree()\n",
    "    poly = PolynomialFeatures(degree=ploinomial_rate, include_bias=True)\n",
    "    X_poly = poly.fit_transform(features)  # (m, p)\n",
    "    m, p = X_poly.shape\n",
    "\n",
    "    # 3) Ініціалізація ваг та накопичувача квадратів градієнтів\n",
    "    theta = np.zeros(p, dtype=float)\n",
    "    eg2 = np.zeros(p, dtype=float)\n",
    "    es = np.zeros(p, dtype=float)\n",
    "    steps = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X_poly @ theta\n",
    "        error = y_pred - y\n",
    "        loss = np.mean(error**2)\n",
    "        grad = (2.0 / m) * (np.transpose(X_poly) @ error)\n",
    "        steps += 1\n",
    "\n",
    "        eg2 = beta2 * eg2 + (1.0 - beta2) * (grad ** 2)\n",
    "        es = beta1 * es + (1.0 - beta1) * grad\n",
    "\n",
    "        es_hat = es / (1.0 - beta1 ** steps)\n",
    "        eg2_hat = eg2 / (1.0 - beta2 ** steps)\n",
    "\n",
    "        theta -= (learning_rate / (np.sqrt(eg2_hat) + epsilon)) * es_hat\n",
    "\n",
    "    return theta\n"
   ],
   "id": "54a09e6ce2dce32c",
   "outputs": [],
   "execution_count": 253
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Функція градієнтного спуску методом NADAM",
   "id": "8bd6ab567cf175aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.299019Z",
     "start_time": "2025-10-01T20:02:15.296108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def polynomial_regression_nadam(features: np.ndarray, poloinomial_func, learning_rate: float, epochs: int, beta1=0.9, beta2=0.999, epsilon = 1e-8):\n",
    "    # 1) Цільові значення з символічного полінома\n",
    "    x1, x2 = symbols('x1 x2')\n",
    "    f = lambdify((x1, x2), poloinomial_func, modules='numpy')\n",
    "    y = f(features[:, 0], features[:, 1]).astype(float).reshape(-1)  # (m,)\n",
    "\n",
    "    # 2) Поліноміальні ознаки узгоджено з іншими функціями (include_bias=True)\n",
    "    ploinomial_rate = Poly(poloinomial_func).total_degree()\n",
    "    poly = PolynomialFeatures(degree=ploinomial_rate, include_bias=True)\n",
    "    X_poly = poly.fit_transform(features)  # (m, p)\n",
    "    m, p = X_poly.shape\n",
    "\n",
    "    # 3) Ініціалізація ваг та моментів\n",
    "    theta = np.zeros(p, dtype=float)\n",
    "    v = np.zeros(p, dtype=float)   # eg2\n",
    "    m1 = np.zeros(p, dtype=float)  # es\n",
    "    steps = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        y_pred = X_poly @ theta\n",
    "        error = y_pred - y\n",
    "        grad = (2.0 / m) * (X_poly.T @ error)\n",
    "        steps += 1\n",
    "\n",
    "        # Оновлення моментів\n",
    "        v = beta2 * v + (1.0 - beta2) * (grad ** 2)\n",
    "        m1 = beta1 * m1 + (1.0 - beta1) * grad\n",
    "\n",
    "        # Bias-corrected\n",
    "        m1_hat = m1 / (1.0 - beta1 ** steps)\n",
    "        v_hat = v / (1.0 - beta2 ** steps)\n",
    "\n",
    "        # Nadam \"погляд уперед\" без подвійної корекції\n",
    "        nesterov = beta1 * m1_hat + (1.0 - beta1) * (grad / (1.0 - beta1 ** steps))\n",
    "\n",
    "        theta -= (learning_rate / (np.sqrt(v_hat) + epsilon)) * nesterov\n",
    "\n",
    "    return theta"
   ],
   "id": "be00c6d77c436f56",
   "outputs": [],
   "execution_count": 254
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Визначаємо функцію прогнозування",
   "id": "1786ea09122fdd29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.302904Z",
     "start_time": "2025-10-01T20:02:15.301220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(X_input: np.ndarray, poloinomial_func, theta: np.ndarray):\n",
    "    # Та сама логіка PolynomialFeatures, що і в train\n",
    "    ploinomial_rate = Poly(poloinomial_func).total_degree()\n",
    "    poly = PolynomialFeatures(degree=ploinomial_rate, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X_input)  # Порядок і набір ознак детерміновані degree і n_features\n",
    "    return X_poly @ theta\n",
    "\n"
   ],
   "id": "934cd6bd3e235b47",
   "outputs": [],
   "execution_count": 255
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Визначаємо функцію, що генерує значення, застосовуючи поліном (реальні значення)",
   "id": "bc7d4a953336734"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.306612Z",
     "start_time": "2025-10-01T20:02:15.305191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def actual_vals(X_input: np.ndarray, poloinomial_func):\n",
    "    x1, x2 = symbols('x1 x2')\n",
    "    polynomial = lambdify((x1, x2), poloinomial_func, modules='numpy')\n",
    "    return polynomial(X_input[:, 0], X_input[:, 1])"
   ],
   "id": "7a32cd8c0d34293e",
   "outputs": [],
   "execution_count": 256
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Застосовуємо прогнозування з функціями градієнтного спуску",
   "id": "6bf4ce4b4d39b39e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.340155Z",
     "start_time": "2025-10-01T20:02:15.308758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_np = np.random.rand(10, 2)\n",
    "pol_func = polynomial()\n",
    "pred_gd = predict(test_np, pol_func, polynomial_regression_gradient_descent(sample_np, pol_func, 0.1, 10000))\n",
    "pred_gd"
   ],
   "id": "f3779d83440cf1fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.57033404,  5.19398438,  1.54102856,  3.92213147,  0.9914736 ,\n",
       "       -0.93754121,  1.37694618,  2.15019474,  0.35300574, -1.08066852])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:15.405138Z",
     "start_time": "2025-10-01T20:02:15.348183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred_rmsprop = predict(test_np, pol_func, polynomial_regression_rmsprop(sample_np, pol_func, 0.02, 10000))\n",
    "pred_rmsprop"
   ],
   "id": "e7c3f3ec54d0f36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.59382322,  5.16088754,  1.50476893,  3.88190488,  0.95671894,\n",
       "       -0.95989257,  1.34213973,  2.11259041,  0.32025665, -1.10682657])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 258
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:17.609296Z",
     "start_time": "2025-10-01T20:02:15.410496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred_sgd = predict(test_np, pol_func, polynomial_regression_SGD(sample_np, pol_func, 0.1, 10000))\n",
    "pred_sgd"
   ],
   "id": "cabeb6c3a277bda6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.571137  ,  5.19255161,  1.5405709 ,  3.92654129,  0.98910946,\n",
       "       -0.93997871,  1.37311636,  2.14998247,  0.3502397 , -1.08289839])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 259
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:17.737945Z",
     "start_time": "2025-10-01T20:02:17.633088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred_adam = predict(test_np, pol_func, polynomial_regression_adam(sample_np, pol_func, 0.02, 10000))\n",
    "pred_adam"
   ],
   "id": "33460b98c6bb45e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.571137  ,  5.19255161,  1.5405709 ,  3.92654129,  0.98910946,\n",
       "       -0.93997871,  1.37311636,  2.14998247,  0.3502397 , -1.08289839])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 260
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:17.834604Z",
     "start_time": "2025-10-01T20:02:17.742319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred_nadam = predict(test_np, pol_func, polynomial_regression_nadam(sample_np, pol_func, 0.02, 10000))\n",
    "pred_nadam"
   ],
   "id": "4229f8efbea852a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.571137  ,  5.1925516 ,  1.54057089,  3.92654128,  0.98910945,\n",
       "       -0.93997871,  1.37311635,  2.14998246,  0.35023969, -1.08289839])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 261
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Обчислюємо реальний результат",
   "id": "650ce25c35f1fb10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:17.853673Z",
     "start_time": "2025-10-01T20:02:17.850633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "actual = actual_vals(test_np, pol_func)\n",
    "actual"
   ],
   "id": "24ee672e9d127c7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.571137  ,  5.19255161,  1.5405709 ,  3.92654129,  0.98910946,\n",
       "       -0.93997871,  1.37311636,  2.14998247,  0.3502397 , -1.08289839])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 262
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Вимірюємо час виконання різних функцій графієнтного спуску",
   "id": "180305ed861d5f8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:19.034965Z",
     "start_time": "2025-10-01T20:02:17.860552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit -r 3\n",
    "predict(test_np, pol_func, polynomial_regression_gradient_descent(sample_np, pol_func, 0.1, 10000))"
   ],
   "id": "c0a11d8c69607fd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.7 ms ± 547 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "execution_count": 263
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:21.227321Z",
     "start_time": "2025-10-01T20:02:19.048063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit -r 3\n",
    "predict(test_np, pol_func, polynomial_regression_rmsprop(sample_np, pol_func, 0.02, 10000))"
   ],
   "id": "6d92319a6d8733d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 ms ± 453 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "execution_count": 264
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:30.025323Z",
     "start_time": "2025-10-01T20:02:21.240329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit -r 3\n",
    "predict(test_np, pol_func, polynomial_regression_SGD(sample_np, pol_func, 0.1, 10000))"
   ],
   "id": "bb84aae00dfcd57d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19 s ± 3.32 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:34.201453Z",
     "start_time": "2025-10-01T20:02:30.037959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit -r 3\n",
    "predict(test_np, pol_func, polynomial_regression_adam(sample_np, pol_func, 0.02, 10000))"
   ],
   "id": "be081c2352e98fdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ms ± 938 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T20:02:37.870477Z",
     "start_time": "2025-10-01T20:02:34.215851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit -r 3\n",
    "predict(test_np, pol_func, polynomial_regression_nadam(sample_np, pol_func, 0.02, 10000))"
   ],
   "id": "e9c845d4f7ae3fa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.1 ms ± 589 μs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "execution_count": 267
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Висновок\n",
    "\n",
    "У цій вправі ми використали наступні методи градієнтного спуску:\n",
    "\n",
    "- Звичайний градієнтний спуск\n",
    "- SGD\n",
    "- RMSProp\n",
    "- ADAM\n",
    "- NADAM\n",
    "\n",
    "Найточніший прогноз дали **SGD** та **ADAM**. За часом виконання найшвидшим виявився звичайний градієнтний спуск (хоча і найменш точний), а найповільнішим - **SGD**."
   ],
   "id": "321b227714943605"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
